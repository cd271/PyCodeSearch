{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "be8687ce-bd43-46be-b222-fd90dc910c4d",
   "metadata": {},
   "source": [
    "This notebook demonstrates the full process of `SemanticCodeSearch` using fine-tuned GraphCodeBERT model, which implement the code-to-code search."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d67703c6-7e3a-4b39-8c76-090f2d7affff",
   "metadata": {
    "id": "Eh1yfA0-Dt-f"
   },
   "source": [
    "### Download test repositories and run `inspect4py` on them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "07d58ea6-3276-4b02-a712-8bc8b0576c45",
   "metadata": {
    "id": "_G--A3sT61LR"
   },
   "outputs": [],
   "source": [
    "# Repository picked from https://github.com as an example\n",
    "repo = 'keon/algorithms'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4c7bc956",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inspect4py, version 0.0.6\n"
     ]
    }
   ],
   "source": [
    "!inspect4py --version"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02acbf2f-54c7-4365-ad68-11405493d1dc",
   "metadata": {},
   "source": [
    "!mkdir -p content/output\n",
    "%cd content/\n",
    "\n",
    "!mkdir -p {repo} && git clone {f\"https://github.com/{repo}.git\"} {repo}\n",
    "!inspect4py -i {repo} -o output/{repo} -sc -rm"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4c21286e-b5d7-47f6-8c73-cd509a458fc3",
   "metadata": {
    "id": "tXCNJRtRKQXP"
   },
   "source": [
    "### Extract docstrings and functions from repositories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d33cf8e0-0e08-4ed9-b857-585eb6e75cb1",
   "metadata": {
    "id": "F-89vQxSFR4s"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def funcs_to_lists(funcs, func_codes, docs):\n",
    "    for func_name, func_info in funcs.items():\n",
    "        if func_info.get(\"source_code\") is not None:\n",
    "            func_codes.append(func_info[\"source_code\"])\n",
    "        if func_info.get(\"doc\") is None:\n",
    "            continue\n",
    "        for key in [\"full\", \"long_description\", \"short_description\"]:\n",
    "            if func_info[\"doc\"].get(key) is not None:\n",
    "                docs.append(f\"{func_name} {func_info['doc'].get(key)}\")\n",
    "                break\n",
    "\n",
    "def file_to_lists(filename):\n",
    "    func_codes = []\n",
    "    docs = []\n",
    "    with open(filename, \"r\") as f:\n",
    "        dic = json.load(f)\n",
    "    dic.pop(\"readme_files\", None)\n",
    "    for dir_name, files in dic.items():\n",
    "        for file in files:\n",
    "            if file.get(\"functions\") is not None:\n",
    "                funcs_to_lists(file[\"functions\"], func_codes, docs)\n",
    "            if file.get(\"classes\") is not None:\n",
    "                for class_name, class_info in file[\"classes\"].items():\n",
    "                    if class_info.get(\"methods\") is not None:\n",
    "                        funcs_to_lists(class_info[\"methods\"], func_codes, docs)\n",
    "    return func_codes, docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4d0f0d9b-143b-4ffb-82e7-7437c10cf042",
   "metadata": {
    "id": "zw0cKz1nKXE1"
   },
   "outputs": [],
   "source": [
    "repo_info = {}\n",
    "function_list, docstring_list = file_to_lists(f\"content/output/{repo}/directory_info.json\")\n",
    "# repo_info[\"docs\"] = docstring_list\n",
    "repo_info[\"funcs\"] = function_list"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "974b901a",
   "metadata": {},
   "source": [
    "### Download UniXCoder, fine-tuned model and install requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4d170f14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !wget https://raw.githubusercontent.com/microsoft/CodeBERT/master/UniXcoder/unixcoder.py"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4ddb750f",
   "metadata": {},
   "source": [
    "### Generate embeddings for all repositories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dac3de1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/cs/home/cd271/codesearch/lib64/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from unixcoder import UniXcoder\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "code_search_model = UniXcoder(\"Lazyhope/unixcoder-nine-advtest\")\n",
    "clone_detection_model = UniXcoder(\"Lazyhope/unixcoder-clone-detection\")\n",
    "code_search_model.to(device)\n",
    "clone_detection_model.to(device)\n",
    "\n",
    "def get_code_embeddings(code, model):\n",
    "    tokens_ids = model.tokenize([code], max_length=512, mode=\"<encoder-only>\")\n",
    "    source_ids = torch.tensor(tokens_ids).to(device)\n",
    "    _, embeddings = code_search_model(source_ids)\n",
    "\n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "27a88798",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Generating func embeddings for repo - \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 1171/1171 [01:02<00:00, 18.81it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "# Generate code embeddings for all funcs in repository\n",
    "print(f\" - Generating func embeddings for repo - \")\n",
    "code_embeddings = []\n",
    "for func in tqdm(repo_info[\"funcs\"]):\n",
    "    code_embeddings.append(get_code_embeddings(func, clone_detection_model))    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9549b586",
   "metadata": {},
   "source": [
    "### Evaluations & Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d1c27a5a-807e-4e8a-b99c-8e47c0868c81",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "def test_topsort(self):\n",
    "    res_recursive = top_sort_recursive(self.depGraph)\n",
    "    self.assertTrue(res_recursive.index('g') < res_recursive.index('e'))\n",
    "    \n",
    "    res_iterative = top_sort(self.depGraph)\n",
    "    self.assertTrue(res_iterative.index('g') < res_iterative.index('e'))\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "af9db4a8-1732-432d-8dff-16192516a8cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import CosineSimilarity\n",
    "\n",
    "input_embedding = get_code_embeddings(query, clone_detection_model)\n",
    "\n",
    "cosine_sim = CosineSimilarity(dim=1, eps=1e-8)\n",
    "# cosine_sim = CosineSimilarity(dim=1)\n",
    "similarities = cosine_sim(input_embedding, torch.stack(code_embeddings))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "eff24d59-a4a7-4b4d-900f-231b676b7f48",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similiar code snippets:\n",
      "\n",
      "------------------------------------------------------------------\n",
      " def test_topsort(self):\n",
      "    res = top_sort_recursive(self.depGraph)\n",
      "    self.assertTrue(res.index('g') < res.index('e'))\n",
      "    res = top_sort(self.depGraph)\n",
      "    self.assertTrue(res.index('g') < res.index('e'))\n",
      "\n",
      "------------------------------------------------------------------\n",
      " def test_gnome_sort(self):\n",
      "    self.assertTrue(is_sorted(gnome_sort([1, 3, 2, 5, 65, 23, 57, 1232])))\n",
      "\n",
      "------------------------------------------------------------------\n",
      " def dfs_transposed(vertex, graph, order, visited):\n",
      "    \"\"\"\n",
      "    Perform a depth first search traversal of the graph starting at the given vertex.\n",
      "    Stores the order in which nodes were visited to the list, in transposed order.\n",
      "    \"\"\"\n",
      "    visited[vertex] = True\n",
      "    for adjacent in graph[vertex]:\n",
      "        if not visited[adjacent]:\n",
      "            dfs_transposed(adjacent, graph, order, visited)\n",
      "    order.append(vertex)\n",
      "\n",
      "------------------------------------------------------------------\n",
      " def postorder_rec(root, res=None):\n",
      "    if root is None:\n",
      "        return []\n",
      "    if res is None:\n",
      "        res = []\n",
      "    postorder_rec(root.left, res)\n",
      "    postorder_rec(root.right, res)\n",
      "    res.append(root.val)\n",
      "    return res\n",
      "\n",
      "------------------------------------------------------------------\n",
      " def decimal_to_binary_util(val):\n",
      "    \"\"\"\n",
      "    Convert 8-bit decimal number to binary representation\n",
      "    :type val: str\n",
      "    :rtype: str\n",
      "    \"\"\"\n",
      "    bits = [128, 64, 32, 16, 8, 4, 2, 1]\n",
      "    val = int(val)\n",
      "    binary_rep = ''\n",
      "    for bit in bits:\n",
      "        if val >= bit:\n",
      "            binary_rep += str(1)\n",
      "            val -= bit\n",
      "        else:\n",
      "            binary_rep += str(0)\n",
      "    return binary_rep\n"
     ]
    }
   ],
   "source": [
    "# Convert similarities tensor to a list\n",
    "similarities_list = similarities.tolist()\n",
    "\n",
    "# Combine functions with cosine similarities\n",
    "func_similarities = list(zip(repo_info[\"funcs\"], similarities_list))\n",
    "\n",
    "# Sort the func_similarities list based on cosine similarities\n",
    "sorted_similarities = sorted(func_similarities, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "num_similar_funcs = 5  # Specify the number of similar functions to retrieve\n",
    "most_similar_funcs = sorted_similarities[:num_similar_funcs]\n",
    "\n",
    "# Extract the function names from the most_similar_funcs list\n",
    "similar_func_names = [func for func, _ in most_similar_funcs]\n",
    "\n",
    "# Output the function names\n",
    "print('Similiar code snippets:')\n",
    "for func_name in similar_func_names:\n",
    "    print(f'\\n------------------------------------------------------------------\\n {func_name}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
