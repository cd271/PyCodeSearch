{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "be8687ce-bd43-46be-b222-fd90dc910c4d",
   "metadata": {},
   "source": [
    "This notebook demonstrates the full process of `SemanticCodeSearch` using fine-tuned GraphCodeBERT model, which implement the code-to-code search."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d67703c6-7e3a-4b39-8c76-090f2d7affff",
   "metadata": {
    "id": "Eh1yfA0-Dt-f"
   },
   "source": [
    "### Download test repositories and run `inspect4py` on them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "07d58ea6-3276-4b02-a712-8bc8b0576c45",
   "metadata": {
    "id": "_G--A3sT61LR"
   },
   "outputs": [],
   "source": [
    "# Repository picked from https://github.com as an example\n",
    "repo = 'keon/algorithms'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4c7bc956",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inspect4py, version 0.0.6\n"
     ]
    }
   ],
   "source": [
    "!inspect4py --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "417fbbfb-6785-49b3-9f30-6f6135191087",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p content/output\n",
    "%cd content/\n",
    "\n",
    "!mkdir -p {repo} && git clone {f\"https://github.com/{repo}.git\"} {repo}\n",
    "!inspect4py -i {repo} -o output/{repo} -sc -rm"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4c21286e-b5d7-47f6-8c73-cd509a458fc3",
   "metadata": {
    "id": "tXCNJRtRKQXP"
   },
   "source": [
    "### Extract docstrings and functions from repositories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d33cf8e0-0e08-4ed9-b857-585eb6e75cb1",
   "metadata": {
    "id": "F-89vQxSFR4s"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def funcs_to_lists(funcs, func_codes, docs):\n",
    "    for func_name, func_info in funcs.items():\n",
    "        if func_info.get(\"source_code\") is not None:\n",
    "            func_codes.append(func_info[\"source_code\"])\n",
    "        if func_info.get(\"doc\") is None:\n",
    "            continue\n",
    "        for key in [\"full\", \"long_description\", \"short_description\"]:\n",
    "            if func_info[\"doc\"].get(key) is not None:\n",
    "                docs.append(f\"{func_name} {func_info['doc'].get(key)}\")\n",
    "                break\n",
    "\n",
    "def file_to_lists(filename):\n",
    "    func_codes = []\n",
    "    docs = []\n",
    "    with open(filename, \"r\") as f:\n",
    "        dic = json.load(f)\n",
    "    dic.pop(\"readme_files\", None)\n",
    "    for dir_name, files in dic.items():\n",
    "        for file in files:\n",
    "            if file.get(\"functions\") is not None:\n",
    "                funcs_to_lists(file[\"functions\"], func_codes, docs)\n",
    "            if file.get(\"classes\") is not None:\n",
    "                for class_name, class_info in file[\"classes\"].items():\n",
    "                    if class_info.get(\"methods\") is not None:\n",
    "                        funcs_to_lists(class_info[\"methods\"], func_codes, docs)\n",
    "    return func_codes, docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4d0f0d9b-143b-4ffb-82e7-7437c10cf042",
   "metadata": {
    "id": "zw0cKz1nKXE1"
   },
   "outputs": [],
   "source": [
    "repo_info = {}\n",
    "function_list, _ = file_to_lists(f\"content/output/{repo}/directory_info.json\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "974b901a",
   "metadata": {},
   "source": [
    "### Download UniXCoder, fine-tuned model and install requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bfffb63c-02df-4384-b41c-3eccb6028d2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/cs/home/cd271/codesearch/lib64/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "\n",
    "model_name = \"Salesforce/codet5-base-multi-sum\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "34d6429a-b851-41c5-88b8-fc313b2585d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_code_sum(funcs):\n",
    "    inputs = tokenizer.batch_encode_plus(\n",
    "        funcs,\n",
    "        padding=True,\n",
    "        truncation=True,\n",
    "        return_tensors=\"pt\"\n",
    "    )\n",
    "    # Perform inference to get code similarity\n",
    "    with torch.no_grad():\n",
    "        inputs = {k: v.to(model.device) for k, v in inputs.items()}\n",
    "        outputs = model.generate(**inputs)\n",
    "        \n",
    "    similar_code_snippets = tokenizer.batch_decode(outputs, skip_special_tokens=True)\n",
    "    return similar_code_snippets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "85b8ab2d-f396-4150-937b-210e2021f90b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating code summaries:   0%|                                                               | 0/1171 [00:00<?, ?it/s]/cs/home/cd271/codesearch/lib64/python3.9/site-packages/transformers/generation/utils.py:1353: UserWarning: Using `max_length`'s default (20) to control the generation length. This behaviour is deprecated and will be removed from the config in v5 of Transformers -- we recommend using `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n",
      "Generating code summaries: 100%|████████████████████████████████████████████████████| 1171/1171 [05:27<00:00,  3.57it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "# Obtain function_list summarizations \n",
    "code_sum = []\n",
    "with tqdm(total=len(function_list), desc=\"Generating code summaries\") as pbar:\n",
    "    for funcs in function_list:\n",
    "        code_snippets = get_code_sum([funcs])\n",
    "        code_sum.extend(code_snippets)\n",
    "        pbar.update(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ed2f4c19-ddbe-4a35-a74d-062d7118e1e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example for input code snippet \n",
    "query = ['def test_bitsum_number_valid(bitsum, sum_signs): \\n return all(val == 0 or val == sum_signs for val in bitsum)']\n",
    "query_sum = get_code_sum(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ee389947-3c76-465b-b06c-505ca17846fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "sum_model = SentenceTransformer(\"all-mpnet-base-v2\", device=device)\n",
    "\n",
    "def get_embedding(code_sum, query_sum):\n",
    "    return sum_model.encode(code_sum, convert_to_tensor=True), sum_model.encode(query_sum, convert_to_tensor=True)\n",
    "    \n",
    "code_sum_embeddings, query_sum_embedding = get_embedding(code_sum, query_sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "359299ed-cac2-4cbf-856f-5933fd7f02ca",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from torch.nn import CosineSimilarity\n",
    "\n",
    "cosine_sim = CosineSimilarity(dim=1)\n",
    "similarities = cosine_sim(query_sum_embedding, code_sum_embeddings).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "522c0424-7d2e-4a9f-9835-770359827e39",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_top_n_index(lst, n):\n",
    "    largest_indices = []\n",
    "    for i in range(n):\n",
    "        max_value = max(lst)\n",
    "        max_index = lst.index(max_value)\n",
    "        largest_indices.append(max_index)\n",
    "        lst[max_index] = float('-inf')\n",
    "    return largest_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "47fc5780-eb32-49ac-9580-0639897c75bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similiar code snippet:\n",
      "\n",
      "Similarity: 0.9090137481689453, \n",
      "def _check_every_number_in_bitsum(bitsum, sum_signs):\n",
      "    for val in bitsum:\n",
      "        if val != 0 and val != sum_signs:\n",
      "            return False\n",
      "    return True \n",
      "--------------------------------------------------------------\n",
      "Similarity: 0.7223002910614014, \n",
      "def test_get_bit(self):\n",
      "    self.assertEqual(1, get_bit(22, 2))\n",
      "    self.assertEqual(0, get_bit(22, 3)) \n",
      "--------------------------------------------------------------\n",
      "Similarity: 0.6739780902862549, \n",
      "def test_has_alternative_bit(self):\n",
      "    self.assertTrue(has_alternative_bit(5))\n",
      "    self.assertFalse(has_alternative_bit(7))\n",
      "    self.assertFalse(has_alternative_bit(11))\n",
      "    self.assertTrue(has_alternative_bit(10)) \n",
      "--------------------------------------------------------------\n",
      "Similarity: 0.66061931848526, \n",
      "def has_alternative_bit_fast(n):\n",
      "    mask1 = int('aaaaaaaa', 16)\n",
      "    mask2 = int('55555555', 16)\n",
      "    return mask1 == n + (n ^ mask1) or mask2 == n + (n ^ mask2) \n",
      "--------------------------------------------------------------\n",
      "Similarity: 0.6407468318939209, \n",
      "def test_has_alternative_bit_fast(self):\n",
      "    self.assertTrue(has_alternative_bit_fast(5))\n",
      "    self.assertFalse(has_alternative_bit_fast(7))\n",
      "    self.assertFalse(has_alternative_bit_fast(11))\n",
      "    self.assertTrue(has_alternative_bit_fast(10)) \n",
      "--------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "sim = similarities.copy()\n",
    "index = find_top_n_index(sim,5)\n",
    "print('Similiar code snippet:\\n')\n",
    "for i in index:\n",
    "    print(f'Similarity: {similarities[i]}, \\n{function_list[i]} \\n--------------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4047214f-528d-401e-ba2c-0414e9b2fc63",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
