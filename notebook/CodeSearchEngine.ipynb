{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0dfa205d-53f8-4a72-9f38-dcc83dbb599f",
   "metadata": {},
   "source": [
    "This notebook demonstrates the full process of `Sematic Code Search`, which contains both `code2code` and `text2code` search paradigms."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f662446-3866-4714-942c-e5a19db6da30",
   "metadata": {},
   "source": [
    "### Prepare Python environment for Code Search Engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "951c660b-dc0d-4f6f-b9cd-c0ea2d99944b",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91be69ec-5fc6-448b-a948-0be24f58e913",
   "metadata": {},
   "source": [
    "# Part 1. Prepare database for search engine"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea406fd5-f399-4ec9-95c3-b00aef6a6042",
   "metadata": {
    "id": "Eh1yfA0-Dt-f"
   },
   "source": [
    "### Download test repository example and run `inspect4py` on it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "19ea1b47-39c0-45ef-9184-0ed87eb512bd",
   "metadata": {
    "id": "_G--A3sT61LR"
   },
   "outputs": [],
   "source": [
    "# Repository picked from https://github.com as an example\n",
    "repo = 'keon/algorithms'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "40ca1684-0508-4133-bd60-bde5d59bf9cd",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/cs/home/cd271/Documents/Project/Examples/SemanticCodeSearch/notebook/content\n",
      "Cloning into 'keon/algorithms'...\n",
      "remote: Enumerating objects: 5162, done.\u001b[K\n",
      "remote: Counting objects: 100% (26/26), done.\u001b[K\n",
      "remote: Compressing objects: 100% (23/23), done.\u001b[K\n",
      "remote: Total 5162 (delta 11), reused 16 (delta 3), pack-reused 5136\u001b[K\n",
      "Receiving objects: 100% (5162/5162), 1.42 MiB | 7.52 MiB/s, done.\n",
      "Resolving deltas: 100% (3230/3230), done.\n",
      "Updating files: 100% (477/477), done.\n",
      "Creating jsDir:output/keon/algorithms/algorithms/json_files\n",
      "Creating jsDir:output/keon/algorithms/algorithms/algorithms/json_files\n",
      "Creating jsDir:output/keon/algorithms/algorithms/algorithms/streaming/json_files\n",
      "Creating jsDir:output/keon/algorithms/algorithms/algorithms/maths/json_files\n",
      "Error when processing polynomial.py:  <class 'AttributeError'>\n",
      "Creating jsDir:output/keon/algorithms/algorithms/algorithms/greedy/json_files\n",
      "Creating jsDir:output/keon/algorithms/algorithms/algorithms/queues/json_files\n",
      "Error when processing queue.py:  <class 'AttributeError'>\n",
      "Error when processing priority_queue.py:  <class 'AttributeError'>\n",
      "Creating jsDir:output/keon/algorithms/algorithms/algorithms/search/json_files\n",
      "Creating jsDir:output/keon/algorithms/algorithms/algorithms/tree/json_files\n",
      "Error when processing longest_consecutive.py:  <class 'AttributeError'>\n",
      "Error when processing deepest_left.py:  <class 'AttributeError'>\n",
      "Error when processing invert_tree.py:  <class 'AttributeError'>\n",
      "Creating jsDir:output/keon/algorithms/algorithms/algorithms/tree/red_black_tree/json_files\n",
      "Error when processing red_black_tree.py:  <class 'AttributeError'>\n",
      "Creating jsDir:output/keon/algorithms/algorithms/algorithms/tree/segment_tree/json_files\n",
      "Creating jsDir:output/keon/algorithms/algorithms/algorithms/tree/trie/json_files\n",
      "Creating jsDir:output/keon/algorithms/algorithms/algorithms/tree/fenwick_tree/json_files\n",
      "Creating jsDir:output/keon/algorithms/algorithms/algorithms/tree/traversal/json_files\n",
      "Creating jsDir:output/keon/algorithms/algorithms/algorithms/tree/avl/json_files\n",
      "Creating jsDir:output/keon/algorithms/algorithms/algorithms/tree/bst/json_files\n",
      "Error when processing kth_smallest.py:  <class 'AttributeError'>\n",
      "Creating jsDir:output/keon/algorithms/algorithms/algorithms/automata/json_files\n",
      "Creating jsDir:output/keon/algorithms/algorithms/algorithms/set/json_files\n",
      "Error when processing randomized_set.py:  <class 'AttributeError'>\n",
      "Creating jsDir:output/keon/algorithms/algorithms/algorithms/bit/json_files\n",
      "Creating jsDir:output/keon/algorithms/algorithms/algorithms/dp/json_files\n",
      "Error when processing longest_increasing.py:  <class 'AttributeError'>\n",
      "Creating jsDir:output/keon/algorithms/algorithms/algorithms/graph/json_files\n",
      "Error when processing path_between_two_vertices_in_digraph.py:  <class 'AttributeError'>\n",
      "Creating jsDir:output/keon/algorithms/algorithms/algorithms/bfs/json_files\n",
      "Creating jsDir:output/keon/algorithms/algorithms/algorithms/strings/json_files\n",
      "Error when processing word_squares.py:  <class 'AttributeError'>\n",
      "Creating jsDir:output/keon/algorithms/algorithms/algorithms/arrays/json_files\n",
      "Creating jsDir:output/keon/algorithms/algorithms/algorithms/unionfind/json_files\n",
      "Error when processing count_islands.py:  <class 'AttributeError'>\n",
      "Creating jsDir:output/keon/algorithms/algorithms/algorithms/backtrack/json_files\n",
      "Error when processing generate_abbreviations.py:  <class 'AttributeError'>\n",
      "Error when processing generate_parenthesis.py:  <class 'AttributeError'>\n",
      "Error when processing palindrome_partitioning.py:  <class 'AttributeError'>\n",
      "Error when processing add_operators.py:  <class 'AttributeError'>\n",
      "Error when processing array_sum_combinations.py:  <class 'AttributeError'>\n",
      "Error when processing find_words.py:  <class 'AttributeError'>\n",
      "Error when processing combination_sum.py:  <class 'AttributeError'>\n",
      "Creating jsDir:output/keon/algorithms/algorithms/algorithms/distribution/json_files\n",
      "Creating jsDir:output/keon/algorithms/algorithms/algorithms/matrix/json_files\n",
      "Error when processing sum_sub_squares.py:  <class 'AttributeError'>\n",
      "Error when processing search_in_sorted_matrix.py:  <class 'AttributeError'>\n",
      "Creating jsDir:output/keon/algorithms/algorithms/algorithms/sort/json_files\n",
      "Error when processing stooge_sort.py:  <class 'AttributeError'>\n",
      "Creating jsDir:output/keon/algorithms/algorithms/algorithms/compression/json_files\n",
      "Added in funct/method elias_generic , argument named unary, number of argument 0\n",
      "Added in funct/method elias_generic , argument named elias_gamma, number of argument 0\n",
      "Creating jsDir:output/keon/algorithms/algorithms/algorithms/ml/json_files\n",
      "Creating jsDir:output/keon/algorithms/algorithms/algorithms/map/json_files\n",
      "Error when processing hashtable.py:  <class 'AttributeError'>\n",
      "Error when processing separate_chaining_hashtable.py:  <class 'AttributeError'>\n",
      "Creating jsDir:output/keon/algorithms/algorithms/algorithms/linkedlist/json_files\n",
      "Creating jsDir:output/keon/algorithms/algorithms/algorithms/unix/json_files\n",
      "Creating jsDir:output/keon/algorithms/algorithms/algorithms/unix/path/json_files\n",
      "Creating jsDir:output/keon/algorithms/algorithms/algorithms/stack/json_files\n",
      "Error when processing stack.py:  <class 'AttributeError'>\n",
      "Creating jsDir:output/keon/algorithms/algorithms/algorithms/dfs/json_files\n",
      "Error when processing walls_and_gates.py:  <class 'AttributeError'>\n",
      "Error when processing pacific_atlantic.py:  <class 'AttributeError'>\n",
      "Error when processing count_islands.py:  <class 'AttributeError'>\n",
      "Creating jsDir:output/keon/algorithms/algorithms/algorithms/heap/json_files\n",
      "Creating jsDir:output/keon/algorithms/algorithms/tests/json_files\n",
      "Error when processing test_polynomial.py:  <class 'AttributeError'>\n",
      "Error when processing test_monomial.py:  <class 'AttributeError'>\n",
      "Creating jsDir:output/keon/algorithms/algorithms/docs/source/json_files\n",
      "Analysis completed\n",
      "Total number of folders processed (root folder is considered a folder): 37\n",
      "Total number of files found:  378\n",
      "Total number of classes found:  269\n",
      "Total number of dependencies found in those files 919\n",
      "Total number of functions parsed:  523\n",
      "/cs/home/cd271/Documents/Project/Examples/SemanticCodeSearch/notebook\n"
     ]
    }
   ],
   "source": [
    "!mkdir -p content/output\n",
    "%cd content/\n",
    "\n",
    "!mkdir -p {repo} && git clone {f\"https://github.com/{repo}.git\"} {repo}\n",
    "!inspect4py -i {repo} -o output/{repo} -sc -rm\n",
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ae47ffd5-52a2-44ea-8506-c3707af25723",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "from search_engine import data_prepare\n",
    "\n",
    "repo_info = {}\n",
    "function_list = data_prepare.file_to_lists(f\"content/output/{repo}/directory_info.json\")\n",
    "repo_info[\"funcs\"] = function_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd623227-4a9e-42ce-af17-bf85617743f5",
   "metadata": {},
   "source": [
    "# Part 2. Code-To-Code Search Engine Interface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cc20c26d-2ed9-4043-8173-23228f239197",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating code embeddings for dataset ... \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 1171/1171 [01:11<00:00, 16.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset code embeddings generated!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from search_engine import model\n",
    "\n",
    "# Instantiate the Code2CodeSearchEngine and compute code_embeddings\n",
    "se_pl = model.Code2CodeSearchEngine(repo_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e037e0d2-b005-4323-8f83-78b4461cbec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.magic import (register_line_magic, register_cell_magic)\n",
    "\n",
    "@register_cell_magic\n",
    "def search_by_code(line, cell):\n",
    "    n = int(input(\"How many similar code snippets you want to retrieve: \"))\n",
    "    se_pl.search(cell, n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "58d895cc-fdfc-4294-be67-61fef7bce20f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "How many similar code snippets you want to retrieve:  5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The most similar 5 code snippets:\n",
      "\n",
      "------------------------------------------------------------------\n",
      " def dfs_traverse(graph, start):\n",
      "    \"\"\"\n",
      "    Traversal by depth first search.\n",
      "    \"\"\"\n",
      "    (visited, stack) = (set(), [start])\n",
      "    while stack:\n",
      "        node = stack.pop()\n",
      "        if node not in visited:\n",
      "            visited.add(node)\n",
      "            for next_node in graph[node]:\n",
      "                if next_node not in visited:\n",
      "                    stack.append(next_node)\n",
      "    return visited\n",
      "\n",
      "------------------------------------------------------------------\n",
      " def dfs_traverse_recursive(graph, start, visited=None):\n",
      "    \"\"\"\n",
      "    Traversal by recursive depth first search.\n",
      "    \"\"\"\n",
      "    if visited is None:\n",
      "        visited = set()\n",
      "    visited.add(start)\n",
      "    for next_node in graph[start]:\n",
      "        if next_node not in visited:\n",
      "            dfs_traverse_recursive(graph, next_node, visited)\n",
      "    return visited\n",
      "\n",
      "------------------------------------------------------------------\n",
      " def bfs_traverse(graph, start):\n",
      "    \"\"\"\n",
      "    Traversal by breadth first search.\n",
      "    \"\"\"\n",
      "    (visited, queue) = (set(), [start])\n",
      "    while queue:\n",
      "        node = queue.pop(0)\n",
      "        if node not in visited:\n",
      "            visited.add(node)\n",
      "            for next_node in graph[node]:\n",
      "                if next_node not in visited:\n",
      "                    queue.append(next_node)\n",
      "    return visited\n",
      "\n",
      "------------------------------------------------------------------\n",
      " def top_sort_recursive(graph):\n",
      "    \"\"\" Time complexity is the same as DFS, which is O(V + E)\n",
      "        Space complexity: O(V)\n",
      "    \"\"\"\n",
      "    (order, enter, state) = ([], set(graph), {})\n",
      "\n",
      "    def dfs(node):\n",
      "        state[node] = GRAY\n",
      "        for k in graph.get(node, ()):\n",
      "            sk = state.get(k, None)\n",
      "            if sk == GRAY:\n",
      "                raise ValueError('cycle')\n",
      "            if sk == BLACK:\n",
      "                continue\n",
      "            enter.discard(k)\n",
      "            dfs(k)\n",
      "        order.append(node)\n",
      "        state[node] = BLACK\n",
      "    while enter:\n",
      "        dfs(enter.pop())\n",
      "    return order\n",
      "\n",
      "------------------------------------------------------------------\n",
      " def test_match_symbol(self):\n",
      "    self.assertEqual(self.result, match_symbol(self.words, self.symbols))\n"
     ]
    }
   ],
   "source": [
    "%%search_by_code\n",
    "\"\"\"\n",
    "def dfs(graph, start_node, visited):\n",
    "    if start_node not in visited:\n",
    "        # Mark the current node as visited.\n",
    "        visited.append(start_node)\n",
    "        print(\"Visited:\", start_node)\n",
    "        # Explore all the adjacent nodes.\n",
    "        for neighbor in graph[start_node]:\n",
    "            dfs(graph, neighbor, visited)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c7dab17-3fd7-454f-9797-8241ee7dd243",
   "metadata": {},
   "source": [
    "# Part 3. Text-to-code Search Engine Interface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "543db5ae-61d3-46de-8db1-dfe817960826",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating code embeddings for dataset ... \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 1171/1171 [01:10<00:00, 16.50it/s]\n",
      "/cs/home/cd271/Documents/Project/Examples/SemanticCodeSearch/notebook/../search_engine/model.py:71: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  code_embeddings = torch.stack([torch.tensor(embedding) for embedding in code_embeddings])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset code embeddings generated!\n"
     ]
    }
   ],
   "source": [
    "# Instantiate the Text2CodeSearchEngine and compute code_embeddings\n",
    "se_nl = model.Text2CodeSearchEngine(repo_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ca70eada-a52f-4075-acc3-2cf29be4d719",
   "metadata": {},
   "outputs": [],
   "source": [
    "@register_cell_magic\n",
    "def search_by_text(line, cell):\n",
    "    n = int(input(\"How many similar code snippets you want to retrieve: \"))\n",
    "    se_nl.search(cell, n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "172c9e3c-e65e-4ec6-8bf6-a2afb46abc9f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "How many similar code snippets you want to retrieve:  5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The most similar 5 code snippets:\n",
      "\n",
      "------------------------------------------------------------------\n",
      " def test_cosine_similarity(self):\n",
      "    vec_a = [1, 1, 1]\n",
      "    vec_b = [-1, -1, -1]\n",
      "    vec_c = [1, 2, -1]\n",
      "    self.assertAlmostEqual(cosine_similarity(vec_a, vec_a), 1)\n",
      "    self.assertAlmostEqual(cosine_similarity(vec_a, vec_b), -1)\n",
      "    self.assertAlmostEqual(cosine_similarity(vec_a, vec_c), 0.4714045208)\n",
      "\n",
      "------------------------------------------------------------------\n",
      " def cosine_similarity(vec1, vec2):\n",
      "    \"\"\"\n",
      "    Calculate cosine similarity between given two vectors\n",
      "    :type vec1: list\n",
      "    :type vec2: list\n",
      "    \"\"\"\n",
      "    if len(vec1) != len(vec2):\n",
      "        raise ValueError('The two vectors must be the same length. Got shape ' + str(len(vec1)) + ' and ' + str(len(vec2)))\n",
      "    norm_a = _l2_distance(vec1)\n",
      "    norm_b = _l2_distance(vec2)\n",
      "    similarity = 0.0\n",
      "    for (vec1_element, vec2_element) in zip(vec1, vec2):\n",
      "        similarity += vec1_element * vec2_element\n",
      "    similarity /= norm_a * norm_b\n",
      "    return similarity\n",
      "\n",
      "------------------------------------------------------------------\n",
      " def lcs(word1, word2, i, j):\n",
      "    \"\"\"\n",
      "    The length of longest common subsequence among the two given strings word1 and word2\n",
      "    \"\"\"\n",
      "    if i == 0 or j == 0:\n",
      "        return 0\n",
      "    if word1[i - 1] == word2[j - 1]:\n",
      "        return 1 + lcs(word1, word2, i - 1, j - 1)\n",
      "    return max(lcs(word1, word2, i - 1, j), lcs(word1, word2, i, j - 1))\n",
      "\n",
      "------------------------------------------------------------------\n",
      " def distance(x, y):\n",
      "    \"\"\"[summary]\n",
      "    HELPER-FUNCTION\n",
      "    calculates the (eulidean) distance between vector x and y.\n",
      "\n",
      "    Arguments:\n",
      "        x {[tuple]} -- [vector]\n",
      "        y {[tuple]} -- [vector]\n",
      "    \"\"\"\n",
      "    assert len(x) == len(y), 'The vector must have same length'\n",
      "    result = ()\n",
      "    sum = 0\n",
      "    for i in range(len(x)):\n",
      "        result += (x[i] - y[i],)\n",
      "    for component in result:\n",
      "        sum += component ** 2\n",
      "    return math.sqrt(sum)\n",
      "\n",
      "------------------------------------------------------------------\n",
      " def _l2_distance(vec):\n",
      "    \"\"\"\n",
      "    Calculate l2 distance from two given vectors.\n",
      "    \"\"\"\n",
      "    norm = 0.0\n",
      "    for element in vec:\n",
      "        norm += element * element\n",
      "    norm = math.sqrt(norm)\n",
      "    return norm\n"
     ]
    }
   ],
   "source": [
    "%%search_by_text\n",
    "Function to calcualte cosine similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31771fda-37ec-4b25-98f0-c28430221254",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
